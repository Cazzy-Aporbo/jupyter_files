{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women's Health Training Split Preparation - Part 4\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is the fourth and final part in a series focused on creating a dataset for training an LLM model to predict better questions for women's health consultations. This part focuses on preparing the analyzed data from Part 3 for LLM training by creating appropriate train/validation/test splits and formatting the data for different LLM frameworks.\n",
    "\n",
    "### Objectives\n",
    "- Load the analyzed data from Part 3\n",
    "- Create balanced train/validation/test splits\n",
    "- Format the data for LLM training\n",
    "- Create evaluation metrics for assessing question quality\n",
    "- Prepare the final dataset package\n",
    "\n",
    "### Why This Matters\n",
    "Proper preparation of training data is crucial for developing an effective LLM model. By creating balanced splits and appropriate formatting, we ensure that our model learns to generate better questions for women's health consultations across a wide range of conditions and demographics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up our environment by importing necessary libraries and loading the analyzed data from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Display versions for reproducibility\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory structure\n",
    "data_dir = 'womens_health_data'\n",
    "raw_dir = os.path.join(data_dir, 'raw')\n",
    "processed_dir = os.path.join(data_dir, 'processed')\n",
    "expanded_dir = os.path.join(data_dir, 'expanded')\n",
    "analysis_dir = os.path.join(data_dir, 'analysis')\n",
    "checkpoint_dir = os.path.join(data_dir, 'checkpoints')\n",
    "figures_dir = os.path.join(data_dir, 'figures')\n",
    "training_dir = os.path.join(data_dir, 'training')\n",
    "output_dir = os.path.join(data_dir, 'output')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [data_dir, raw_dir, processed_dir, expanded_dir, analysis_dir, checkpoint_dir, figures_dir, training_dir, output_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Let's create some helper functions for data splitting, formatting, and checkpoint management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(df, name):\n",
    "    \"\"\"\n",
    "    Save a dataframe as a checkpoint CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to save\n",
    "    - name: name of the checkpoint (without extension)\n",
    "    \n",
    "    Returns:\n",
    "    - path: path to the saved file\n",
    "    \"\"\"\n",
    "    # Create the full path with timestamp to avoid overwriting\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{name}_{timestamp}.csv\"\n",
    "    path = os.path.join(checkpoint_dir, filename)\n",
    "    \n",
    "    # Save the dataframe\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Checkpoint saved: {path}\")\n",
    "    \n",
    "    # Also save a version with a fixed name for easy loading\n",
    "    fixed_path = os.path.join(checkpoint_dir, f\"{name}_latest.csv\")\n",
    "    df.to_csv(fixed_path, index=False)\n",
    "    print(f\"Latest version saved: {fixed_path}\")\n",
    "    \n",
    "    return path\n",
    "\n",
    "def load_checkpoint(name):\n",
    "    \"\"\"\n",
    "    Load the latest checkpoint for a given name.\n",
    "    \n",
    "    Parameters:\n",
    "    - name: name of the checkpoint (without extension)\n",
    "    \n",
    "    Returns:\n",
    "    - df: loaded DataFrame or None if file doesn't exist\n",
    "    \"\"\"\n",
    "    path = os.path.join(checkpoint_dir, f\"{name}_latest.csv\")\n",
    "    \n",
    "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"Checkpoint loaded: {path}\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            return df\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: Checkpoint file exists but is empty: {path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Checkpoint not found or empty: {path}\")\n",
    "        return None\n",
    "\n",
    "def verify_dataframe(df, name):\n",
    "    \"\"\"\n",
    "    Verify a dataframe by displaying basic information.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to verify\n",
    "    - name: name of the dataframe for display purposes\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- {name} Verification ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nData types:\")\n",
    "    display(df.dtypes)\n",
    "    print(\"\\nMissing values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    display(missing[missing > 0] if any(missing > 0) else \"No missing values\")\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    display(df.describe(include='all').T)\n",
    "    print(\"----------------------------\\n\")\n",
    "\n",
    "def format_for_llm_training(row, format_type='instruction'):\n",
    "    \"\"\"\n",
    "    Format a row of data for LLM training.\n",
    "    \n",
    "    Parameters:\n",
    "    - row: pandas Series containing a row of data\n",
    "    - format_type: type of formatting to use ('instruction', 'chat', 'completion')\n",
    "    \n",
    "    Returns:\n",
    "    - formatted_data: formatted data for LLM training\n",
    "    \"\"\"\n",
    "    if format_type == 'instruction':\n",
    "        # Format for instruction tuning (e.g., Alpaca format)\n",
    "        instruction = \"Transform this dismissed women's health question into a better, more specific question that is less likely to be dismissed by healthcare providers.\"\n",
    "        input_text = f\"Dismissed Question: {row['DismissedQuestion']}\\nCondition: {row['Condition']}\\nCategory: {row['Category']}\"\n",
    "        output_text = f\"Better Question: {row['BetterQuestion']}\"\n",
    "        \n",
    "        formatted_data = {\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": input_text,\n",
    "            \"output\": output_text\n",
    "        }\n",
    "    \n",
    "    elif format_type == 'chat':\n",
    "        # Format for chat tuning (e.g., ChatML format)\n",
    "        system_message = \"You are a helpful assistant that transforms vague or easily dismissed women's health questions into better, more specific questions that are less likely to be dismissed by healthcare providers.\"\n",
    "        user_message = f\"I need help improving this question for my doctor about my {row['Condition']} (Category: {row['Category']}): '{row['DismissedQuestion']}'\"\n",
    "        assistant_message = f\"Here's a better way to ask your question: '{row['BetterQuestion']}'\"\n",
    "        \n",
    "        formatted_data = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "                {\"role\": \"assistant\", \"content\": assistant_message}\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    elif format_type == 'completion':\n",
    "        # Format for completion tuning (e.g., GPT format)\n",
    "        prompt = f\"Transform this dismissed women's health question into a better, more specific question that is less likely to be dismissed by healthcare providers.\\n\\nDismissed Question: {row['DismissedQuestion']}\\nCondition: {row['Condition']}\\nCategory: {row['Category']}\\n\\nBetter Question:\"\n",
    "        completion = f\" {row['BetterQuestion']}\"\n",
    "        \n",
    "        formatted_data = {\n",
    "            \"prompt\": prompt,\n",
    "            \"completion\": completion\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown format type: {format_type}\")\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "def save_jsonl(data, filename):\n",
    "    \"\"\"\n",
    "    Save data as a JSONL file.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: list of JSON-serializable objects\n",
    "    - filename: name of the file to save\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    print(f\"Saved {len(data)} items to {filename}\")\n",
    "\n",
    "def calculate_category_distribution(df, category_col='Category'):\n",
    "    \"\"\"\n",
    "    Calculate the distribution of categories in a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - category_col: name of the category column\n",
    "    \n",
    "    Returns:\n",
    "    - distribution: dictionary mapping categories to percentages\n",
    "    \"\"\"\n",
    "    counts = df[category_col].value_counts()\n",
    "    total = counts.sum()\n",
    "    distribution = {category: (count / total) * 100 for category, count in counts.items()}\n",
    "    return distribution\n",
    "\n",
    "def calculate_distribution_difference(dist1, dist2):\n",
    "    \"\"\"\n",
    "    Calculate the difference between two distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - dist1: first distribution (dictionary)\n",
    "    - dist2: second distribution (dictionary)\n",
    "    \n",
    "    Returns:\n",
    "    - difference: average absolute difference in percentages\n",
    "    \"\"\"\n",
    "    all_categories = set(dist1.keys()) | set(dist2.keys())\n",
    "    differences = []\n",
    "    \n",
    "    for category in all_categories:\n",
    "        pct1 = dist1.get(category, 0)\n",
    "        pct2 = dist2.get(category, 0)\n",
    "        differences.append(abs(pct1 - pct2))\n",
    "    \n",
    "    return sum(differences) / len(differences) if differences else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Analyzed Data\n",
    "\n",
    "Let's load the analyzed data from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformation analysis data\n",
    "transformation_path = os.path.join(analysis_dir, 'transformation_analysis.csv')\n",
    "if os.path.exists(transformation_path):\n",
    "    transformation_df = pd.read_csv(transformation_path)\n",
    "    print(f\"Loaded transformation analysis data: {transformation_df.shape}\")\n",
    "else:\n",
    "    print(\"Transformation analysis data not found. Please run Part 3 first.\")\n",
    "    transformation_df = None\n",
    "\n",
    "# Load the text analysis data\n",
    "text_analysis_path = os.path.join(analysis_dir, 'text_analysis.csv')\n",
    "if os.path.exists(text_analysis_path):\n",
    "    text_analysis_df = pd.read_csv(text_analysis_path)\n",
    "    print(f\"Loaded text analysis data: {text_analysis_df.shape}\")\n",
    "else:\n",
    "    print(\"Text analysis data not found. Please run Part 3 first.\")\n",
    "    text_analysis_df = None\n",
    "\n",
    "# Load the demographic analysis data\n",
    "demographic_path = os.path.join(analysis_dir, 'demographic_analysis.csv')\n",
    "if os.path.exists(demographic_path):\n",
    "    demographic_df = pd.read_csv(demographic_path)\n",
    "    print(f\"Loaded demographic analysis data: {demographic_df.shape}\")\n",
    "else:\n",
    "    print(\"Demographic analysis data not found. Please run Part 3 first.\")\n",
    "    demographic_df = None\n",
    "\n",
    "# Load the analysis summary\n",
    "analysis_summary_path = os.path.join(analysis_dir, 'analysis_summary.json')\n",
    "if os.path.exists(analysis_summary_path):\n",
    "    with open(analysis_summary_path, 'r') as f:\n",
    "        analysis_summary = json.load(f)\n",
    "    print(\"Loaded analysis summary\")\n",
    "else:\n",
    "    print(\"Analysis summary not found. Please run Part 3 first.\")\n",
    "    analysis_summary = None\n",
    "\n",
    "# Load the key factors\n",
    "key_factors_path = os.path.join(analysis_dir, 'key_factors.json')\n",
    "if os.path.exists(key_factors_path):\n",
    "    with open(key_factors_path, 'r') as f:\n",
    "        key_factors = json.load(f)\n",
    "    print(\"Loaded key factors\")\n",
    "else:\n",
    "    print(\"Key factors not found. Please run Part 3 first.\")\n",
    "    key_factors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the loaded data\n",
    "if transformation_df is not None:\n",
    "    verify_dataframe(transformation_df, \"Transformation Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Training\n",
    "\n",
    "Let's prepare the data for LLM training by selecting the relevant columns and ensuring data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the training data\n",
    "training_data_df = load_checkpoint(\"training_data\")\n",
    "\n",
    "# If not, prepare the training data\n",
    "if training_data_df is None and transformation_df is not None:\n",
    "    # Select the relevant columns for training\n",
    "    training_columns = [\n",
    "        'DismissedQuestion', 'BetterQuestion', 'Condition', 'Category',\n",
    "        'DismissalFrequency', 'DiagnosisDelay', 'AgeGroup', 'RacialEthnicConsiderations',\n",
    "        'Comorbidities', 'ConditionDemographicRiskNotes'\n",
    "    ]\n",
    "    \n",
    "    # Create a copy of the transformation dataframe with only the relevant columns\n",
    "    training_data_df = transformation_df[training_columns].copy()\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = training_data_df.isnull().sum()\n",
    "    print(\"Missing values:\")\n",
    "    print(missing_values[missing_values > 0] if any(missing_values > 0) else \"No missing values\")\n",
    "    \n",
    "    # Fill missing values\n",
    "    if any(missing_values > 0):\n",
    "        # Fill missing Comorbidities and ConditionDemographicRiskNotes with empty strings\n",
    "        if 'Comorbidities' in missing_values and missing_values['Comorbidities'] > 0:\n",
    "            training_data_df['Comorbidities'] = training_data_df['Comorbidities'].fillna('')\n",
    "        \n",
    "        if 'ConditionDemographicRiskNotes' in missing_values and missing_values['ConditionDemographicRiskNotes'] > 0:\n",
    "            training_data_df['ConditionDemographicRiskNotes'] = training_data_df['ConditionDemographicRiskNotes'].fillna('')\n",
    "    \n",
    "    # Add a unique ID for each example\n",
    "    training_data_df['ExampleID'] = [f\"WH{i:04d}\" for i in range(1, len(training_data_df) + 1)]\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(training_data_df, \"training_data\")\n",
    "else:\n",
    "    print(\"Using existing training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the training data\n",
    "if training_data_df is not None:\n",
    "    verify_dataframe(training_data_df, \"Training Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Train/Validation/Test Splits\n",
    "\n",
    "Let's create balanced train/validation/test splits for our LLM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the split data\n",
    "train_df = load_checkpoint(\"train_data\")\n",
    "val_df = load_checkpoint(\"val_data\")\n",
    "test_df = load_checkpoint(\"test_data\")\n",
    "\n",
    "# If not, create the splits\n",
    "if (train_df is None or val_df is None or test_df is None) and training_data_df is not None:\n",
    "    # Define the split ratios\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.15\n",
    "    \n",
    "    # Create a stratified split based on Category\n",
    "    # First, split into train and temp (val + test)\n",
    "    train_df, temp_df = train_test_split(\n",
    "        training_data_df,\n",
    "        test_size=(val_ratio + test_ratio),\n",
    "        random_state=42,\n",
    "        stratify=training_data_df['Category']\n",
    "    )\n",
    "    \n",
    "    # Then split temp into val and test\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=test_ratio / (val_ratio + test_ratio),\n",
    "        random_state=42,\n",
    "        stratify=temp_df['Category']\n",
    "    )\n",
    "    \n",
    "    # Print the split sizes\n",
    "    print(f\"Training set size: {len(train_df)} ({len(train_df) / len(training_data_df) * 100:.1f}%)\")\n",
    "    print(f\"Validation set size: {len(val_df)} ({len(val_df) / len(training_data_df) * 100:.1f}%)\")\n",
    "    print(f\"Test set size: {len(test_df)} ({len(test_df) / len(training_data_df) * 100:.1f}%)\")\n",
    "    \n",
    "    # Save checkpoints\n",
    "    save_checkpoint(train_df, \"train_data\")\n",
    "    save_checkpoint(val_df, \"val_data\")\n",
    "    save_checkpoint(test_df, \"test_data\")\n",
    "else:\n",
    "    print(\"Using existing split data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the split data\n",
    "if train_df is not None:\n",
    "    verify_dataframe(train_df, \"Training Set\")\n",
    "    \n",
    "if val_df is not None:\n",
    "    verify_dataframe(val_df, \"Validation Set\")\n",
    "    \n",
    "if test_df is not None:\n",
    "    verify_dataframe(test_df, \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the category distribution in each split\n",
    "if train_df is not None and val_df is not None and test_df is not None:\n",
    "    # Calculate the category distributions\n",
    "    train_dist = calculate_category_distribution(train_df)\n",
    "    val_dist = calculate_category_distribution(val_df)\n",
    "    test_dist = calculate_category_distribution(test_df)\n",
    "    full_dist = calculate_category_distribution(training_data_df)\n",
    "    \n",
    "    # Calculate the distribution differences\n",
    "    train_diff = calculate_distribution_difference(train_dist, full_dist)\n",
    "    val_diff = calculate_distribution_difference(val_dist, full_dist)\n",
    "    test_diff = calculate_distribution_difference(test_dist, full_dist)\n",
    "    \n",
    "    print(f\"Average distribution difference - Train: {train_diff:.2f}%, Val: {val_diff:.2f}%, Test: {test_diff:.2f}%\")\n",
    "    \n",
    "    # Create a dataframe for plotting\n",
    "    categories = list(full_dist.keys())\n",
    "    plot_data = []\n",
    "    \n",
    "    for category in categories:\n",
    "        plot_data.append({\n",
    "            'Category': category,\n",
    "            'Full Dataset': full_dist.get(category, 0),\n",
    "            'Training Set': train_dist.get(category, 0),\n",
    "            'Validation Set': val_dist.get(category, 0),\n",
    "            'Test Set': test_dist.get(category, 0)\n",
    "        })\n",
    "    \n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Melt the dataframe for easier plotting\n",
    "    melted_df = pd.melt(plot_df, id_vars=['Category'], var_name='Dataset', value_name='Percentage')\n",
    "    \n",
    "    # Plot the category distribution\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x='Category', y='Percentage', hue='Dataset', data=melted_df)\n",
    "    plt.title('Category Distribution Across Datasets', fontsize=16)\n",
    "    plt.xlabel('Category', fontsize=12)\n",
    "    plt.ylabel('Percentage (%)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Dataset')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'category_distribution_across_datasets.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dismissal frequency distribution in each split\n",
    "if train_df is not None and val_df is not None and test_df is not None:\n",
    "    # Calculate the dismissal frequency distributions\n",
    "    train_dismissal = train_df['DismissalFrequency'].value_counts(normalize=True) * 100\n",
    "    val_dismissal = val_df['DismissalFrequency'].value_counts(normalize=True) * 100\n",
    "    test_dismissal = test_df['DismissalFrequency'].value_counts(normalize=True) * 100\n",
    "    full_dismissal = training_data_df['DismissalFrequency'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # Create a dataframe for plotting\n",
    "    dismissal_levels = ['Low', 'Medium', 'High', 'Very High']\n",
    "    dismissal_data = []\n",
    "    \n",
    "    for level in dismissal_levels:\n",
    "        dismissal_data.append({\n",
    "            'DismissalFrequency': level,\n",
    "            'Full Dataset': full_dismissal.get(level, 0),\n",
    "            'Training Set': train_dismissal.get(level, 0),\n",
    "            'Validation Set': val_dismissal.get(level, 0),\n",
    "            'Test Set': test_dismissal.get(level, 0)\n",
    "        })\n",
    "    \n",
    "    dismissal_df = pd.DataFrame(dismissal_data)\n",
    "    \n",
    "    # Melt the dataframe for easier plotting\n",
    "    melted_dismissal = pd.melt(dismissal_df, id_vars=['DismissalFrequency'], var_name='Dataset', value_name='Percentage')\n",
    "    \n",
    "    # Define the order for dismissal frequency\n",
    "    order = ['Low', 'Medium', 'High', 'Very High']\n",
    "    melted_dismissal['DismissalFrequency'] = pd.Categorical(melted_dismissal['DismissalFrequency'], categories=order, ordered=True)\n",
    "    \n",
    "    # Plot the dismissal frequency distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='DismissalFrequency', y='Percentage', hue='Dataset', data=melted_dismissal)\n",
    "    plt.title('Dismissal Frequency Distribution Across Datasets', fontsize=16)\n",
    "    plt.xlabel('Dismissal Frequency', fontsize=12)\n",
    "    plt.ylabel('Percentage (%)', fontsize=12)\n",
    "    plt.legend(title='Dataset')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'dismissal_frequency_distribution_across_datasets.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Format Data for LLM Training\n",
    "\n",
    "Let's format the data for different LLM training frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training directory structure\n",
    "instruction_dir = os.path.join(training_dir, 'instruction_format')\n",
    "chat_dir = os.path.join(training_dir, 'chat_format')\n",
    "completion_dir = os.path.join(training_dir, 'completion_format')\n",
    "\n",
    "for directory in [instruction_dir, chat_dir, completion_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for instruction tuning\n",
    "if train_df is not None and val_df is not None and test_df is not None:\n",
    "    # Format the training data\n",
    "    train_instruction = [format_for_llm_training(row, format_type='instruction') for _, row in train_df.iterrows()]\n",
    "    val_instruction = [format_for_llm_training(row, format_type='instruction') for _, row in val_df.iterrows()]\n",
    "    test_instruction = [format_for_llm_training(row, format_type='instruction') for _, row in test_df.iterrows()]\n",
    "    \n",
    "    # Save the formatted data\n",
    "    save_jsonl(train_instruction, os.path.join(instruction_dir, 'train.jsonl'))\n",
    "    save_jsonl(val_instruction, os.path.join(instruction_dir, 'val.jsonl'))\n",
    "    save_jsonl(test_instruction, os.path.join(instruction_dir, 'test.jsonl'))\n",
    "    \n",
    "    # Display an example\n",
    "    print(\"\\nExample of instruction format:\")\n",
    "    print(json.dumps(train_instruction[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for chat tuning\n",
    "if train_df is not None and val_df is not None and test_df is not None:\n",
    "    # Format the training data\n",
    "    train_chat = [format_for_llm_training(row, format_type='chat') for _, row in train_df.iterrows()]\n",
    "    val_chat = [format_for_llm_training(row, format_type='chat') for _, row in val_df.iterrows()]\n",
    "    test_chat = [format_for_llm_training(row, format_type='chat') for _, row in test_df.iterrows()]\n",
    "    \n",
    "    # Save the formatted data\n",
    "    save_jsonl(train_chat, os.path.join(chat_dir, 'train.jsonl'))\n",
    "    save_jsonl(val_chat, os.path.join(chat_dir, 'val.jsonl'))\n",
    "    save_jsonl(test_chat, os.path.join(chat_dir, 'test.jsonl'))\n",
    "    \n",
    "    # Display an example\n",
    "    print(\"\\nExample of chat format:\")\n",
    "    print(json.dumps(train_chat[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for completion tuning\n",
    "if train_df is not None and val_df is not None and test_df is not None:\n",
    "    # Format the training data\n",
    "    train_completion = [format_for_llm_training(row, format_type='completion') for _, row in train_df.iterrows()]\n",
    "    val_completion = [format_for_llm_training(row, format_type='completion') for _, row in val_df.iterrows()]\n",
    "    test_completion = [format_for_llm_training(row, format_type='completion') for _, row in test_df.iterrows()]\n",
    "    \n",
    "    # Save the formatted data\n",
    "    save_jsonl(train_completion, os.path.join(completion_dir, 'train.jsonl'))\n",
    "    save_jsonl(val_completion, os.path.join(completion_dir, 'val.jsonl'))\n",
    "    save_jsonl(test_completion, os.path.join(completion_dir, 'test.jsonl'))\n",
    "    \n",
    "    # Display an example\n",
    "    print(\"\\nExample of completion format:\")\n",
    "    print(json.dumps(train_completion[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Evaluation Metrics\n",
    "\n",
    "Let's create evaluation metrics for assessing question quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation metrics based on our analysis\n",
    "evaluation_metrics = {\n",
    "    \"length_ratio\": {\n",
    "        \"description\": \"Ratio of generated question length to original question length\",\n",
    "        \"target\": float(analysis_summary[\"text_analysis\"][\"avg_better_words\"] / analysis_summary[\"text_analysis\"][\"avg_dismissed_words\"]),\n",
    "        \"min_acceptable\": 2.0,\n",
    "        \"calculation\": \"len(generated_question.split()) / len(original_question.split())\"\n",
    "    },\n",
    "    \"specificity_score\": {\n",
    "        \"description\": \"Measure of question specificity based on unique word ratio\",\n",
    "        \"target\": float(analysis_summary[\"text_analysis\"][\"avg_better_specificity\"]),\n",
    "        \"min_acceptable\": 0.7,\n",
    "        \"calculation\": \"len(set(generated_question.split())) / len(generated_question.split())\"\n",
    "    },\n",
    "    \"medical_term_count\": {\n",
    "        \"description\": \"Number of medical terms included in the question\",\n",
    "        \"target\": float(analysis_summary[\"transformation_analysis\"][\"avg_word_increase\"]),\n",
    "        \"min_acceptable\": 3,\n",
    "        \"calculation\": \"sum(1 for term in medical_terms if term.lower() in generated_question.lower())\"\n",
    "    },\n",
    "    \"sentence_count\": {\n",
    "        \"description\": \"Number of sentences in the question\",\n",
    "        \"target\": float(analysis_summary[\"text_analysis\"][\"avg_better_sentences\"]),\n",
    "        \"min_acceptable\": 2,\n",
    "        \"calculation\": \"len(sent_tokenize(generated_question))\"\n",
    "    },\n",
    "    \"complexity_score\": {\n",
    "        \"description\": \"Measure of question complexity based on sentence count and word length\",\n",
    "        \"target\": float(analysis_summary[\"text_analysis\"][\"avg_better_complexity\"]),\n",
    "        \"min_acceptable\": 10,\n",
    "        \"calculation\": \"len(sent_tokenize(generated_question)) * (sum(len(word) for word in generated_question.split()) / len(generated_question.split()))\"\n",
    "    },\n",
    "    \"context_inclusion\": {\n",
    "        \"description\": \"Whether the question includes context about symptoms, duration, and impact\",\n",
    "        \"target\": 1.0,\n",
    "        \"min_acceptable\": 0.8,\n",
    "        \"calculation\": \"binary score based on presence of symptom details, duration, and impact description\"\n",
    "    },\n",
    "    \"similarity_to_original\": {\n",
    "        \"description\": \"Semantic similarity to the original question to ensure the core intent is preserved\",\n",
    "        \"target\": float(analysis_summary[\"text_analysis\"][\"avg_dismissed_specificity\"]),\n",
    "        \"min_acceptable\": 0.5,\n",
    "        \"calculation\": \"cosine_similarity(vectorize(original_question), vectorize(generated_question))\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the evaluation metrics as JSON\n",
    "with open(os.path.join(training_dir, 'evaluation_metrics.json'), 'w') as f:\n",
    "    json.dump(evaluation_metrics, f, indent=2)\n",
    "\n",
    "print(\"Evaluation metrics saved to:\", os.path.join(training_dir, 'evaluation_metrics.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the evaluation metrics\n",
    "print(\"\\n--- Evaluation Metrics for Question Quality ---\")\n",
    "for metric, details in evaluation_metrics.items():\n",
    "    print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Description: {details['description']}\")\n",
    "    print(f\"  Target: {details['target']:.2f}\")\n",
    "    print(f\"  Minimum Acceptable: {details['min_acceptable']}\")\n",
    "    print(f\"  Calculation: {details['calculation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Dataset Documentation\n",
    "\n",
    "Let's create documentation for the dataset to help users understand its structure and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a README file\n",
    "readme_content = f\"\"\"\n",
    "# Women's Health LLM Dataset\n",
    "\n",
    "## Overview\n",
    "\n",
    "This dataset is designed for training LLM models to generate better questions for women's health consultations. It contains pairs of dismissed questions and better alternatives, along with relevant metadata about conditions, categories, and demographic context.\n",
    "\n",
    "## Dataset Statistics\n",
    "\n",
    "- Total examples: {len(training_data_df) if training_data_df is not None else 'N/A'}\n",
    "- Training set: {len(train_df) if train_df is not None else 'N/A'} examples ({len(train_df) / len(training_data_df) * 100:.1f}% if training_data_df is not None and train_df is not None else 'N/A')\n",
    "- Validation set: {len(val_df) if val_df is not None else 'N/A'} examples ({len(val_df) / len(training_data_df) * 100:.1f}% if training_data_df is not None and val_df is not None else 'N/A')\n",
    "- Test set: {len(test_df) if test_df is not None else 'N/A'} examples ({len(test_df) / len(training_data_df) * 100:.1f}% if training_data_df is not None and test_df is not None else 'N/A')\n",
    "- Categories: {', '.join(training_data_df['Category'].unique()) if training_data_df is not None else 'N/A'}\n",
    "- Conditions: {len(training_data_df['Condition'].unique()) if training_data_df is not None else 'N/A'} unique conditions\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "Based on our analysis, we found that better questions for women's health consultations have the following characteristics:\n",
    "\n",
    "1. **Length**: Better questions are {analysis_summary['transformation_analysis']['avg_length_increase_pct']:.0f}% longer than dismissed questions\n",
    "2. **Specificity**: Better questions are {analysis_summary['text_analysis']['avg_better_specificity'] / analysis_summary['text_analysis']['avg_dismissed_specificity']:.1f}x more specific\n",
    "3. **Structure**: Better questions contain {analysis_summary['text_analysis']['avg_better_sentences']:.1f} sentences on average\n",
    "4. **Medical Terminology**: Better questions include {analysis_summary['transformation_analysis']['avg_word_increase']:.1f} more words, many of which are medical terms\n",
    "5. **Context**: Better questions provide context about symptoms, duration, and impact on daily life\n",
    "\n",
    "## Data Format\n",
    "\n",
    "The dataset is provided in three formats for different LLM training approaches:\n",
    "\n",
    "1. **Instruction Format**: For instruction tuning (e.g., Alpaca format)\n",
    "2. **Chat Format**: For chat tuning (e.g., ChatML format)\n",
    "3. **Completion Format**: For completion tuning (e.g., GPT format)\n",
    "\n",
    "Each format includes train, validation, and test splits in JSONL format.\n",
    "\n",
    "## Directory Structure\n",
    "\n",
    "```\n",
    "womens_health_data/\n",
    "├── training/\n",
    "│   ├── instruction_format/\n",
    "│   │   ├── train.jsonl\n",
    "│   │   ├── val.jsonl\n",
    "│   │   └── test.jsonl\n",
    "│   ├── chat_format/\n",
    "│   │   ├── train.jsonl\n",
    "│   │   ├── val.jsonl\n",
    "│   │   └── test.jsonl\n",
    "│   ├── completion_format/\n",
    "│   │   ├── train.jsonl\n",
    "│   │   ├── val.jsonl\n",
    "│   │   └── test.jsonl\n",
    "│   └── evaluation_metrics.json\n",
    "├── raw/\n",
    "│   └── ... (raw data files)\n",
    "├── processed/\n",
    "│   └── ... (processed data files)\n",
    "├── expanded/\n",
    "│   └── ... (expanded data files)\n",
    "├── analysis/\n",
    "│   ├── transformation_analysis.csv\n",
    "│   ├── text_analysis.csv\n",
    "│   ├── demographic_analysis.csv\n",
    "│   ├── analysis_summary.json\n",
    "│   └── key_factors.json\n",
    "└── figures/\n",
    "    └── ... (visualization figures)\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "# Load the training data\n",
    "with open('womens_health_data/training/instruction_format/train.jsonl', 'r') as f:\n",
    "    train_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Load the validation data\n",
    "with open('womens_health_data/training/instruction_format/val.jsonl', 'r') as f:\n",
    "    val_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Load the test data\n",
    "with open('womens_health_data/training/instruction_format/test.jsonl', 'r') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "```\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "The `evaluation_metrics.json` file contains metrics for evaluating the quality of generated questions. These metrics are based on our analysis of what makes a question less likely to be dismissed by healthcare providers.\n",
    "\n",
    "## License\n",
    "\n",
    "This dataset is provided for research and educational purposes only. It does not contain any personally identifiable information.\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use this dataset in your research, please cite it as follows:\n",
    "\n",
    "```\n",
    "@dataset{womens_health_llm_dataset,\n",
    "  title={Women's Health LLM Dataset},\n",
    "  author={Your Name},\n",
    "  year={2025},\n",
    "  month={April}\n",
    "}\n",
    "```\n",
    "\n",
    "## Contact\n",
    "\n",
    "For questions or feedback about this dataset, please contact [your email].\n",
    "\"\"\"\n",
    "\n",
    "# Save the README file\n",
    "with open(os.path.join(training_dir, 'README.md'), 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"README saved to:\", os.path.join(training_dir, 'README.md'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data dictionary\n",
    "data_dictionary_content = \"\"\"\n",
    "# Women's Health LLM Dataset - Data Dictionary\n",
    "\n",
    "## Original Data Fields\n",
    "\n",
    "| Field | Description | Type | Example |\n",
    "| ----- | ----------- | ---- | ------- |\n",
    "| ExampleID | Unique identifier for each example | string | WH0001 |\n",
    "| DismissedQuestion | Original question that is likely to be dismissed | string | \"I'm tired all the time.\" |\n",
    "| BetterQuestion | Improved version of the question that is less likely to be dismissed | string | \"I've been experiencing persistent fatigue for the past 3 months that isn't relieved by rest. It's affecting my ability to work and exercise. Could this be related to my thyroid condition or another underlying issue?\" |\n",
    "| Condition | Medical condition related to the question | string | \"Chronic Fatigue Syndrome\" |\n",
    "| Category | Broader category of the condition | string | \"Chronic Pain/Fatigue\" |\n",
    "| DismissalFrequency | How often questions about this condition are dismissed | string | \"High\" |\n",
    "| DiagnosisDelay | Average time (in years) to diagnosis for this condition | float | 4.5 |\n",
    "| AgeGroup | Age group most affected by this condition | string | \"25-34\" |\n",
    "| RacialEthnicConsiderations | Racial/ethnic considerations for this condition | string | \"Black/African American\" |\n",
    "| Comorbidities | Common comorbidities associated with this condition | string | \"Depression; Anxiety; Irritable Bowel Syndrome\" |\n",
    "| ConditionDemographicRiskNotes | Notes on demographic risk factors for this condition | string | \"More common in women aged 30-50; often misdiagnosed as depression.\" |\n",
    "\n",
    "## Instruction Format Fields\n",
    "\n",
    "| Field | Description | Type | Example |\n",
    "| ----- | ----------- | ---- | ------- |\n",
    "| instruction | Task instruction for the model | string | \"Transform this dismissed women's health question into a better, more specific question that is less likely to be dismissed by healthcare providers.\" |\n",
    "| input | Input text containing the dismissed question and context | string | \"Dismissed Question: I'm tired all the time.\\nCondition: Chronic Fatigue Syndrome\\nCategory: Chronic Pain/Fatigue\" |\n",
    "| output | Expected output text containing the better question | string | \"Better Question: I've been experiencing persistent fatigue for the past 3 months that isn't relieved by rest. It's affecting my ability to work and exercise. Could this be related to my thyroid condition or another underlying issue?\" |\n",
    "\n",
    "## Chat Format Fields\n",
    "\n",
    "| Field | Description | Type | Example |\n",
    "| ----- | ----------- | ---- | ------- |\n",
    "| messages | Array of message objects | array | [system_message, user_message, assistant_message] |\n",
    "| messages[0].role | Role of the first message | string | \"system\" |\n",
    "| messages[0].content | Content of the system message | string | \"You are a helpful assistant that transforms vague or easily dismissed women's health questions into better, more specific questions that are less likely to be dismissed by healthcare providers.\" |\n",
    "| messages[1].role | Role of the second message | string | \"user\" |\n",
    "| messages[1].content | Content of the user message | string | \"I need help improving this question for my doctor about my Chronic Fatigue Syndrome (Category: Chronic Pain/Fatigue): 'I'm tired all the time.'\" |\n",
    "| messages[2].role | Role of the third message | string | \"assistant\" |\n",
    "| messages[2].content | Content of the assistant message | string | \"Here's a better way to ask your question: 'I've been experiencing persistent fatigue for the past 3 months that isn't relieved by rest. It's affecting my ability to work and exercise. Could this be related to my thyroid condition or another underlying issue?'\" |\n",
    "\n",
    "## Completion Format Fields\n",
    "\n",
    "| Field | Description | Type | Example |\n",
    "| ----- | ----------- | ---- | ------- |\n",
    "| prompt | Prompt text for the model | string | \"Transform this dismissed women's health question into a better, more specific question that is less likely to be dismissed by healthcare providers.\\n\\nDismissed Question: I'm tired all the time.\\nCondition: Chronic Fatigue Syndrome\\nCategory: Chronic Pain/Fatigue\\n\\nBetter Question:\" |\n",
    "| completion | Expected completion text | string | \" I've been experiencing persistent fatigue for the past 3 months that isn't relieved by rest. It's affecting my ability to work and exercise. Could this be related to my thyroid condition or another underlying issue?\" |\n",
    "\"\"\"\n",
    "\n",
    "# Save the data dictionary\n",
    "with open(os.path.join(training_dir, 'DATA_DICTIONARY.md'), 'w') as f:\n",
    "    f.write(data_dictionary_content)\n",
    "\n",
    "print(\"Data dictionary saved to:\", os.path.join(training_dir, 'DATA_DICTIONARY.md'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Final Dataset Package\n",
    "\n",
    "Let's prepare the final dataset package for distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for the final dataset package\n",
    "package_dir = os.path.join(output_dir, 'Womens_Health_LLM_Dataset')\n",
    "os.makedirs(package_dir, exist_ok=True)\n",
    "print(f\"Created directory: {package_dir}\")\n",
    "\n",
    "# Create subdirectories\n",
    "package_training_dir = os.path.join(package_dir, 'training')\n",
    "package_analysis_dir = os.path.join(package_dir, 'analysis')\n",
    "package_figures_dir = os.path.join(package_dir, 'figures')\n",
    "package_documentation_dir = os.path.join(package_dir, 'documentation')\n",
    "\n",
    "for directory in [package_training_dir, package_analysis_dir, package_figures_dir, package_documentation_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the training data\n",
    "shutil.copytree(os.path.join(training_dir, 'instruction_format'), os.path.join(package_training_dir, 'instruction_format'))\n",
    "shutil.copytree(os.path.join(training_dir, 'chat_format'), os.path.join(package_training_dir, 'chat_format'))\n",
    "shutil.copytree(os.path.join(training_dir, 'completion_format'), os.path.join(package_training_dir, 'completion_format'))\n",
    "shutil.copy(os.path.join(training_dir, 'evaluation_metrics.json'), os.path.join(package_training_dir, 'evaluation_metrics.json'))\n",
    "print(\"Copied training data\")\n",
    "\n",
    "# Copy the analysis data\n",
    "for file in ['transformation_analysis.csv', 'text_analysis.csv', 'demographic_analysis.csv', 'analysis_summary.json', 'key_factors.json']:\n",
    "    shutil.copy(os.path.join(analysis_dir, file), os.path.join(package_analysis_dir, file))\n",
    "print(\"Copied analysis data\")\n",
    "\n",
    "# Copy the figures\n",
    "for file in os.listdir(figures_dir):\n",
    "    if file.endswith('.png'):\n",
    "        shutil.copy(os.path.join(figures_dir, file), os.path.join(package_figures_dir, file))\n",
    "print(\"Copied figures\")\n",
    "\n",
    "# Copy the documentation\n",
    "shutil.copy(os.path.join(training_dir, 'README.md'), os.path.join(package_dir, 'README.md'))\n",
    "shutil.copy(os.path.join(training_dir, 'DATA_DICTIONARY.md'), os.path.join(package_documentation_dir, 'DATA_DICTIONARY.md'))\n",
    "print(\"Copied documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of the dataset package\n",
    "package_summary = {\n",
    "    \"dataset_name\": \"Women's Health LLM Dataset\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"created_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"total_examples\": len(training_data_df) if training_data_df is not None else 0,\n",
    "    \"train_examples\": len(train_df) if train_df is not None else 0,\n",
    "    \"val_examples\": len(val_df) if val_df is not None else 0,\n",
    "    \"test_examples\": len(test_df) if test_df is not None else 0,\n",
    "    \"categories\": list(training_data_df['Category'].unique()) if training_data_df is not None else [],\n",
    "    \"conditions\": list(training_data_df['Condition'].unique()) if training_data_df is not None else [],\n",
    "    \"formats\": [\"instruction\", \"chat\", \"completion\"],\n",
    "    \"key_metrics\": {\n",
    "        \"avg_length_ratio\": float(analysis_summary[\"text_analysis\"][\"avg_better_words\"] / analysis_summary[\"text_analysis\"][\"avg_dismissed_words\"]),\n",
    "        \"avg_specificity_ratio\": float(analysis_summary[\"text_analysis\"][\"avg_better_specificity\"] / analysis_summary[\"text_analysis\"][\"avg_dismissed_specificity\"]),\n",
    "        \"avg_sentence_count\": float(analysis_summary[\"text_analysis\"][\"avg_better_sentences\"]),\n",
    "        \"avg_word_increase\": float(analysis_summary[\"transformation_analysis\"][\"avg_word_increase\"]),\n",
    "        \"avg_complexity_increase\": float(analysis_summary[\"transformation_analysis\"][\"avg_complexity_increase\"])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the package summary\n",
    "with open(os.path.join(package_dir, 'dataset_summary.json'), 'w') as f:\n",
    "    json.dump(package_summary, f, indent=2)\n",
    "\n",
    "print(\"Package summary saved to:\", os.path.join(package_dir, 'dataset_summary.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file of the dataset package\n",
    "zip_path = os.path.join(output_dir, 'Womens_Health_LLM_Dataset.zip')\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(package_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, os.path.dirname(package_dir))\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"Dataset package created: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've prepared the analyzed data from Part 3 for LLM training:\n",
    "\n",
    "1. **Data Preparation**: We selected the relevant columns and ensured data quality for LLM training.\n",
    "\n",
    "2. **Train/Validation/Test Splits**: We created balanced splits for training, validation, and testing, ensuring that each split has a similar distribution of categories and dismissal frequencies.\n",
    "\n",
    "3. **Data Formatting**: We formatted the data for different LLM training frameworks, including instruction tuning, chat tuning, and completion tuning.\n",
    "\n",
    "4. **Evaluation Metrics**: We created evaluation metrics for assessing question quality based on our analysis of what makes a question less likely to be dismissed.\n",
    "\n",
    "5. **Dataset Documentation**: We created comprehensive documentation for the dataset, including a README file and a data dictionary.\n",
    "\n",
    "6. **Final Dataset Package**: We prepared a final dataset package for distribution, including all the necessary files and documentation.\n",
    "\n",
    "The dataset is now ready for use in training an LLM model to generate better questions for women's health consultations. The model can be trained using any of the provided formats, and the evaluation metrics can be used to assess the quality of the generated questions.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To use this dataset for LLM training:\n",
    "\n",
    "1. Choose an appropriate LLM framework (e.g., Alpaca, ChatML, GPT)\n",
    "2. Load the corresponding formatted data\n",
    "3. Fine-tune the model using the training set\n",
    "4. Evaluate the model using the validation set and the provided evaluation metrics\n",
    "5. Test the final model on the test set\n",
    "\n",
    "The resulting model should be able to generate better questions for women's health consultations that are less likely to be dismissed by healthcare providers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
