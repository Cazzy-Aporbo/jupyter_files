{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women's Health Data Preprocessing - Part 2\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is the second in a series focused on creating a dataset for training an LLM model to predict better questions for women's health consultations. This part focuses on preprocessing the data collected in Part 1.\n",
    "\n",
    "### Objectives\n",
    "- Load the data collected in Part 1\n",
    "- Clean and preprocess the data\n",
    "- Expand the dismissed questions dataset\n",
    "- Add demographic context to the data\n",
    "- Analyze question characteristics\n",
    "- Implement save points throughout the process\n",
    "\n",
    "### Why This Matters\n",
    "Proper preprocessing is essential for creating a high-quality dataset that can effectively train an LLM model. By expanding the dismissed questions dataset and adding demographic context, we can create a more comprehensive and balanced dataset that addresses a wider range of women's health concerns across different demographic groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up our environment by importing necessary libraries and loading the data collected in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Display versions for reproducibility\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"NLTK version: {nltk.__version__}\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory structure\n",
    "data_dir = 'womens_health_data'\n",
    "raw_dir = os.path.join(data_dir, 'raw')\n",
    "processed_dir = os.path.join(data_dir, 'processed')\n",
    "checkpoint_dir = os.path.join(data_dir, 'checkpoints')\n",
    "expanded_dir = os.path.join(data_dir, 'expanded')\n",
    "figures_dir = os.path.join(data_dir, 'figures')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [data_dir, raw_dir, processed_dir, checkpoint_dir, expanded_dir, figures_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Let's create some helper functions for saving and loading checkpoints, as well as for text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(df, name):\n",
    "    \"\"\"\n",
    "    Save a dataframe as a checkpoint CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to save\n",
    "    - name: name of the checkpoint (without extension)\n",
    "    \n",
    "    Returns:\n",
    "    - path: path to the saved file\n",
    "    \"\"\"\n",
    "    # Create the full path with timestamp to avoid overwriting\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{name}_{timestamp}.csv\"\n",
    "    path = os.path.join(checkpoint_dir, filename)\n",
    "    \n",
    "    # Save the dataframe\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Checkpoint saved: {path}\")\n",
    "    \n",
    "    # Also save a version with a fixed name for easy loading\n",
    "    fixed_path = os.path.join(checkpoint_dir, f\"{name}_latest.csv\")\n",
    "    df.to_csv(fixed_path, index=False)\n",
    "    print(f\"Latest version saved: {fixed_path}\")\n",
    "    \n",
    "    return path\n",
    "\n",
    "def load_checkpoint(name):\n",
    "    \"\"\"\n",
    "    Load the latest checkpoint for a given name.\n",
    "    \n",
    "    Parameters:\n",
    "    - name: name of the checkpoint (without extension)\n",
    "    \n",
    "    Returns:\n",
    "    - df: loaded DataFrame or None if file doesn't exist\n",
    "    \"\"\"\n",
    "    path = os.path.join(checkpoint_dir, f\"{name}_latest.csv\")\n",
    "    \n",
    "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"Checkpoint loaded: {path}\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            return df\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: Checkpoint file exists but is empty: {path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Checkpoint not found or empty: {path}\")\n",
    "        return None\n",
    "\n",
    "def verify_dataframe(df, name):\n",
    "    \"\"\"\n",
    "    Verify a dataframe by displaying basic information.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to verify\n",
    "    - name: name of the dataframe for display purposes\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- {name} Verification ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nData types:\")\n",
    "    display(df.dtypes)\n",
    "    print(\"\\nMissing values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    display(missing[missing > 0] if any(missing > 0) else \"No missing values\")\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    display(df.describe(include='all').T)\n",
    "    print(\"----------------------------\\n\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by converting to lowercase, removing punctuation and stopwords.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: text to preprocess\n",
    "    \n",
    "    Returns:\n",
    "    - processed_text: preprocessed text\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "def calculate_text_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - text1: first text\n",
    "    - text2: second text\n",
    "    \n",
    "    Returns:\n",
    "    - similarity: cosine similarity score\n",
    "    \"\"\"\n",
    "    if not isinstance(text1, str) or not isinstance(text2, str):\n",
    "        return 0.0\n",
    "    \n",
    "    # Create a CountVectorizer\n",
    "    vectorizer = CountVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(vectors)[0, 1]\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data from Part 1\n",
    "\n",
    "Let's load the data we collected in Part 1 from the processed directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clinical trials data\n",
    "clinical_trials_path = os.path.join(processed_dir, 'clinical_trials.csv')\n",
    "if os.path.exists(clinical_trials_path):\n",
    "    clinical_trials_df = pd.read_csv(clinical_trials_path)\n",
    "    print(f\"Loaded clinical trials data: {clinical_trials_df.shape}\")\n",
    "else:\n",
    "    print(\"Clinical trials data not found. Please run Part 1 first.\")\n",
    "    clinical_trials_df = None\n",
    "\n",
    "# Load PubMed data\n",
    "pubmed_path = os.path.join(processed_dir, 'pubmed.csv')\n",
    "if os.path.exists(pubmed_path):\n",
    "    pubmed_df = pd.read_csv(pubmed_path)\n",
    "    print(f\"Loaded PubMed data: {pubmed_df.shape}\")\n",
    "else:\n",
    "    print(\"PubMed data not found. Please run Part 1 first.\")\n",
    "    pubmed_df = None\n",
    "\n",
    "# Load dismissed questions data\n",
    "dismissed_questions_path = os.path.join(processed_dir, 'dismissed_questions.csv')\n",
    "if os.path.exists(dismissed_questions_path):\n",
    "    dismissed_questions_df = pd.read_csv(dismissed_questions_path)\n",
    "    print(f\"Loaded dismissed questions data: {dismissed_questions_df.shape}\")\n",
    "else:\n",
    "    print(\"Dismissed questions data not found. Please run Part 1 first.\")\n",
    "    dismissed_questions_df = None\n",
    "\n",
    "# Load medical terminology data\n",
    "medical_terminology_path = os.path.join(processed_dir, 'medical_terminology.csv')\n",
    "if os.path.exists(medical_terminology_path):\n",
    "    medical_terminology_df = pd.read_csv(medical_terminology_path)\n",
    "    print(f\"Loaded medical terminology data: {medical_terminology_df.shape}\")\n",
    "else:\n",
    "    print(\"Medical terminology data not found. Please run Part 1 first.\")\n",
    "    medical_terminology_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the loaded data\n",
    "if clinical_trials_df is not None:\n",
    "    verify_dataframe(clinical_trials_df, \"Clinical Trials\")\n",
    "    \n",
    "if pubmed_df is not None:\n",
    "    verify_dataframe(pubmed_df, \"PubMed Publications\")\n",
    "    \n",
    "if dismissed_questions_df is not None:\n",
    "    verify_dataframe(dismissed_questions_df, \"Dismissed Questions\")\n",
    "    \n",
    "if medical_terminology_df is not None:\n",
    "    verify_dataframe(medical_terminology_df, \"Medical Terminology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Question Characteristics\n",
    "\n",
    "Let's analyze the characteristics of the dismissed questions and better questions to understand the differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the analyzed questions data\n",
    "analyzed_questions_df = load_checkpoint(\"analyzed_questions\")\n",
    "\n",
    "# If not, analyze the questions\n",
    "if analyzed_questions_df is None and dismissed_questions_df is not None:\n",
    "    # Create a copy of the dismissed questions dataframe\n",
    "    analyzed_questions_df = dismissed_questions_df.copy()\n",
    "    \n",
    "    # Calculate the length of each question\n",
    "    analyzed_questions_df['DismissedQuestion_Length'] = analyzed_questions_df['DismissedQuestion'].str.len()\n",
    "    analyzed_questions_df['BetterQuestion_Length'] = analyzed_questions_df['BetterQuestion'].str.len()\n",
    "    \n",
    "    # Calculate the ratio of better question length to dismissed question length\n",
    "    analyzed_questions_df['Question_Length_Ratio'] = analyzed_questions_df['BetterQuestion_Length'] / analyzed_questions_df['DismissedQuestion_Length']\n",
    "    \n",
    "    # Preprocess the questions for text analysis\n",
    "    analyzed_questions_df['DismissedQuestion_Processed'] = analyzed_questions_df['DismissedQuestion'].apply(preprocess_text)\n",
    "    analyzed_questions_df['BetterQuestion_Processed'] = analyzed_questions_df['BetterQuestion'].apply(preprocess_text)\n",
    "    \n",
    "    # Calculate the similarity between dismissed and better questions\n",
    "    analyzed_questions_df['Question_Similarity'] = analyzed_questions_df.apply(\n",
    "        lambda row: calculate_text_similarity(row['DismissedQuestion_Processed'], row['BetterQuestion_Processed']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Extract medical terms from the questions\n",
    "    # We'll use the medical terminology dataframe to identify medical terms\n",
    "    if medical_terminology_df is not None:\n",
    "        medical_terms = medical_terminology_df['Term'].str.lower().tolist()\n",
    "        \n",
    "        # Function to count medical terms in a text\n",
    "        def count_medical_terms(text, terms):\n",
    "            if not isinstance(text, str):\n",
    "                return 0\n",
    "            text_lower = text.lower()\n",
    "            count = sum(1 for term in terms if term.lower() in text_lower)\n",
    "            return count\n",
    "        \n",
    "        # Count medical terms in each question\n",
    "        analyzed_questions_df['DismissedQuestion_MedicalTerms'] = analyzed_questions_df['DismissedQuestion'].apply(\n",
    "            lambda x: count_medical_terms(x, medical_terms)\n",
    "        )\n",
    "        analyzed_questions_df['BetterQuestion_MedicalTerms'] = analyzed_questions_df['BetterQuestion'].apply(\n",
    "            lambda x: count_medical_terms(x, medical_terms)\n",
    "        )\n",
    "        \n",
    "        # Calculate the difference in medical terms\n",
    "        analyzed_questions_df['MedicalTerms_Difference'] = analyzed_questions_df['BetterQuestion_MedicalTerms'] - analyzed_questions_df['DismissedQuestion_MedicalTerms']\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(analyzed_questions_df, \"analyzed_questions\")\n",
    "else:\n",
    "    print(\"Using existing analyzed questions data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the analyzed questions data\n",
    "if analyzed_questions_df is not None:\n",
    "    verify_dataframe(analyzed_questions_df, \"Analyzed Questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the question length comparison\n",
    "if analyzed_questions_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create a bar chart\n",
    "    avg_dismissed_length = analyzed_questions_df['DismissedQuestion_Length'].mean()\n",
    "    avg_better_length = analyzed_questions_df['BetterQuestion_Length'].mean()\n",
    "    avg_ratio = analyzed_questions_df['Question_Length_Ratio'].mean()\n",
    "    \n",
    "    bars = plt.bar(['Dismissed Question', 'Better Question'], \n",
    "                   [avg_dismissed_length, avg_better_length],\n",
    "                   color=['#ff7f0e', '#2ca02c'])\n",
    "    \n",
    "    plt.title('Average Question Length Comparison', fontsize=16)\n",
    "    plt.ylabel('Average Length (characters)', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                 f'{height:.1f}',\n",
    "                 ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Add ratio annotation\n",
    "    plt.annotate(f'Better questions are on average {avg_ratio:.1f}x longer than dismissed questions',\n",
    "                xy=(0.5, 0.9), xycoords='axes fraction',\n",
    "                ha='center', va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "                fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'question_length_comparison.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the medical terms comparison\n",
    "if analyzed_questions_df is not None and 'MedicalTerms_Difference' in analyzed_questions_df.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create a bar chart\n",
    "    avg_dismissed_terms = analyzed_questions_df['DismissedQuestion_MedicalTerms'].mean()\n",
    "    avg_better_terms = analyzed_questions_df['BetterQuestion_MedicalTerms'].mean()\n",
    "    avg_diff = analyzed_questions_df['MedicalTerms_Difference'].mean()\n",
    "    \n",
    "    bars = plt.bar(['Dismissed Question', 'Better Question'], \n",
    "                   [avg_dismissed_terms, avg_better_terms],\n",
    "                   color=['#ff7f0e', '#2ca02c'])\n",
    "    \n",
    "    plt.title('Average Medical Terms Comparison', fontsize=16)\n",
    "    plt.ylabel('Average Number of Medical Terms', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{height:.1f}',\n",
    "                 ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Add difference annotation\n",
    "    plt.annotate(f'Better questions contain on average {avg_diff:.1f} more medical terms',\n",
    "                xy=(0.5, 0.9), xycoords='axes fraction',\n",
    "                ha='center', va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),\n",
    "                fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'medical_terms_comparison.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the question similarity distribution\n",
    "if analyzed_questions_df is not None and 'Question_Similarity' in analyzed_questions_df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a histogram\n",
    "    plt.hist(analyzed_questions_df['Question_Similarity'], bins=10, color='#1f77b4', alpha=0.7)\n",
    "    \n",
    "    plt.title('Distribution of Similarity Between Dismissed and Better Questions', fontsize=16)\n",
    "    plt.xlabel('Cosine Similarity', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_similarity = analyzed_questions_df['Question_Similarity'].mean()\n",
    "    plt.axvline(mean_similarity, color='red', linestyle='--', linewidth=2)\n",
    "    plt.text(mean_similarity + 0.02, plt.ylim()[1] * 0.9, \n",
    "             f'Mean: {mean_similarity:.2f}', \n",
    "             color='red', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'question_similarity_histogram.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Expand Dismissed Questions Dataset\n",
    "\n",
    "Now let's expand the dismissed questions dataset to include more examples across different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the expanded questions data\n",
    "expanded_questions_df = load_checkpoint(\"expanded_questions\")\n",
    "\n",
    "# If not, expand the dataset\n",
    "if expanded_questions_df is None and dismissed_questions_df is not None:\n",
    "    # Start with the original dismissed questions\n",
    "    expanded_questions_df = dismissed_questions_df.copy()\n",
    "    \n",
    "    # Add more examples to cover additional conditions and categories\n",
    "    additional_questions = [\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm having trouble getting pregnant.\",\n",
    "            \"BetterQuestion\": \"My partner and I have been trying to conceive for 14 months with regular unprotected intercourse. I'm 32 years old and have regular periods. I've tracked my ovulation using basal body temperature and ovulation predictor kits. Should we be evaluated for fertility issues, and what specific tests would you recommend for both of us?\",\n",
    "            \"Condition\": \"Infertility\",\n",
    "            \"Category\": \"Reproductive Health\",\n",
    "            \"DismissalFrequency\": \"Medium\",\n",
    "            \"DiagnosisDelay\": 2.8,\n",
    "            \"AgeGroup\": \"25-34\",\n",
    "            \"RacialEthnicConsiderations\": \"White/Caucasian\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm bleeding between periods.\",\n",
    "            \"BetterQuestion\": \"I've been experiencing spotting between periods for the past 3 months. The bleeding is light but lasts for 2-3 days and occurs midway between my regular periods. I'm 47 years old and have no other symptoms. Could this be perimenopause, fibroids, or something that requires further investigation?\",\n",
    "            \"Condition\": \"Abnormal Uterine Bleeding\",\n",
    "            \"Category\": \"Reproductive Health\",\n",
    "            \"DismissalFrequency\": \"Medium\",\n",
    "            \"DiagnosisDelay\": 1.9,\n",
    "            \"AgeGroup\": \"45-54\",\n",
    "            \"RacialEthnicConsiderations\": \"Black/African American\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm having memory problems.\",\n",
    "            \"BetterQuestion\": \"I'm 52 and have been experiencing increasing difficulty with short-term memory and word-finding over the past 6 months. It's affecting my work performance. I'm also having night sweats and irregular periods. Could these cognitive changes be related to perimenopause, or should I be concerned about early-onset dementia given my family history?\",\n",
    "            \"Condition\": \"Perimenopausal Cognitive Changes\",\n",
    "            \"Category\": \"Menopause/Aging\",\n",
    "            \"DismissalFrequency\": \"High\",\n",
    "            \"DiagnosisDelay\": 3.2,\n",
    "            \"AgeGroup\": \"45-54\",\n",
    "            \"RacialEthnicConsiderations\": \"Asian\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm losing my hair.\",\n",
    "            \"BetterQuestion\": \"I've noticed significant hair thinning at my crown and temples over the past 8 months. I'm 38 and have a regular menstrual cycle, but I've also been experiencing fatigue and cold intolerance. My mother had thyroid issues. Could my hair loss be related to a thyroid condition, female pattern hair loss, or another hormonal imbalance?\",\n",
    "            \"Condition\": \"Female Pattern Hair Loss\",\n",
    "            \"Category\": \"Autoimmune Conditions\",\n",
    "            \"DismissalFrequency\": \"Medium\",\n",
    "            \"DiagnosisDelay\": 2.5,\n",
    "            \"AgeGroup\": \"35-44\",\n",
    "            \"RacialEthnicConsiderations\": \"Hispanic/Latina\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I feel anxious all the time.\",\n",
    "            \"BetterQuestion\": \"I've been experiencing persistent anxiety with physical symptoms including racing heart, shortness of breath, and insomnia for the past 4 months. These symptoms worsen before my period and are interfering with my daily activities. I have a family history of anxiety disorders. Could this be generalized anxiety disorder, PMDD, or a hormonal imbalance? What diagnostic approach would you recommend?\",\n",
    "            \"Condition\": \"Generalized Anxiety Disorder\",\n",
    "            \"Category\": \"Mental Health\",\n",
    "            \"DismissalFrequency\": \"High\",\n",
    "            \"DiagnosisDelay\": 3.9,\n",
    "            \"AgeGroup\": \"25-34\",\n",
    "            \"RacialEthnicConsiderations\": \"White/Caucasian\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I have a lump in my breast.\",\n",
    "            \"BetterQuestion\": \"I discovered a firm, pea-sized lump in my right breast near the armpit that doesn't move when touched. It wasn't there during my self-exam last month. I'm 42 with no family history of breast cancer, but my maternal aunt had ovarian cancer. The lump isn't painful but feels different from my normal breast tissue. How urgently should this be evaluated, and what specific imaging would you recommend?\",\n",
    "            \"Condition\": \"Breast Mass\",\n",
    "            \"Category\": \"Gynecological Cancers\",\n",
    "            \"DismissalFrequency\": \"Low\",\n",
    "            \"DiagnosisDelay\": 0.8,\n",
    "            \"AgeGroup\": \"35-44\",\n",
    "            \"RacialEthnicConsiderations\": \"Black/African American\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm having trouble sleeping.\",\n",
    "            \"BetterQuestion\": \"I've been experiencing difficulty falling asleep and staying asleep for the past 3 months. I wake up 3-4 times per night, often with night sweats, and feel unrested in the morning. I'm 51 and my periods have become irregular. Could these sleep disturbances be related to perimenopause? What treatment options might help without increasing my risk of breast cancer, which runs in my family?\",\n",
    "            \"Condition\": \"Perimenopausal Insomnia\",\n",
    "            \"Category\": \"Menopause/Aging\",\n",
    "            \"DismissalFrequency\": \"Medium\",\n",
    "            \"DiagnosisDelay\": 2.3,\n",
    "            \"AgeGroup\": \"45-54\",\n",
    "            \"RacialEthnicConsiderations\": \"White/Caucasian\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm having trouble with sex after having a baby.\",\n",
    "            \"BetterQuestion\": \"I gave birth vaginally 6 months ago and am still experiencing pain during intercourse, along with vaginal dryness despite using lubricant. I'm breastfeeding and haven't had a period yet. The pain is sharp and occurs at the entrance of my vagina. I also notice pain when inserting tampons. Could this be related to hormonal changes from breastfeeding, pelvic floor issues, or inadequate healing from a small tear during delivery?\",\n",
    "            \"Condition\": \"Postpartum Dyspareunia\",\n",
    "            \"Category\": \"Pregnancy/Postpartum\",\n",
    "            \"DismissalFrequency\": \"High\",\n",
    "            \"DiagnosisDelay\": 4.1,\n",
    "            \"AgeGroup\": \"25-34\",\n",
    "            \"RacialEthnicConsiderations\": \"Asian\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I'm having dizzy spells.\",\n",
    "            \"BetterQuestion\": \"I've been experiencing recurrent episodes of dizziness and lightheadedness for the past 2 months, particularly when standing up quickly or after prolonged standing. I sometimes feel my heart racing and see spots before my eyes. I'm 29 with low blood pressure historically, and these episodes are worse during my period. Could this be POTS, anemia, or another condition that affects women more frequently?\",\n",
    "            \"Condition\": \"Postural Orthostatic Tachycardia Syndrome\",\n",
    "            \"Category\": \"Cardiovascular Health\",\n",
    "            \"DismissalFrequency\": \"Very High\",\n",
    "            \"DiagnosisDelay\": 5.8,\n",
    "            \"AgeGroup\": \"25-34\",\n",
    "            \"RacialEthnicConsiderations\": \"White/Caucasian\"\n",
    "        },\n",
    "        {\n",
    "            \"DismissedQuestion\": \"I have no interest in sex anymore.\",\n",
    "            \"BetterQuestion\": \"I've experienced a complete loss of sexual desire for the past year that's causing distress in my relationship. I'm 37, in a stable relationship, and not taking any medications known to affect libido. I don't feel depressed but do feel fatigued. My periods are regular. Could this be female sexual interest/arousal disorder, a hormonal imbalance, or related to another underlying condition? What testing would you recommend?\",\n",
    "            \"Condition\": \"Female Sexual Interest/Arousal Disorder\",\n",
    "            \"Category\": \"Sexual Health\",\n",
    "            \"DismissalFrequency\": \"High\",\n",
    "            \"DiagnosisDelay\": 4.7,\n",
    "            \"AgeGroup\": \"35-44\",\n",
    "            \"RacialEthnicConsiderations\": \"Hispanic/Latina\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add the additional questions to the dataframe\n",
    "    additional_questions_df = pd.DataFrame(additional_questions)\n",
    "    expanded_questions_df = pd.concat([expanded_questions_df, additional_questions_df], ignore_index=True)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(expanded_questions_df, \"expanded_questions\")\n",
    "else:\n",
    "    print(\"Using existing expanded questions data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the expanded questions data\n",
    "if expanded_questions_df is not None:\n",
    "    verify_dataframe(expanded_questions_df, \"Expanded Questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the category distribution in the expanded dataset\n",
    "if expanded_questions_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Count the categories\n",
    "    category_counts = expanded_questions_df['Category'].value_counts()\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(category_counts.index, category_counts.values, \n",
    "                   color=sns.color_palette(\"viridis\", len(category_counts)))\n",
    "    \n",
    "    plt.title('Distribution of Categories in Expanded Dataset', fontsize=16)\n",
    "    plt.xlabel('Category', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'expanded_categories_distribution.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dismissal frequency distribution in the expanded dataset\n",
    "if expanded_questions_df is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Define the order for dismissal frequency\n",
    "    order = ['Very High', 'High', 'Medium', 'Low']\n",
    "    \n",
    "    # Count the frequencies\n",
    "    dismissal_counts = expanded_questions_df['DismissalFrequency'].value_counts().reindex(order)\n",
    "    \n",
    "    # Create a color map based on severity\n",
    "    colors = ['#d62728', '#ff7f0e', '#ffbb78', '#2ca02c']\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(dismissal_counts.index, dismissal_counts.values, color=colors)\n",
    "    \n",
    "    plt.title('Distribution of Dismissal Frequencies in Expanded Dataset', fontsize=16)\n",
    "    plt.xlabel('Dismissal Frequency', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'expanded_dismissal_frequencies.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Demographic Context\n",
    "\n",
    "Now let's add more demographic context to the expanded questions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the demographic context data\n",
    "demographic_context_df = load_checkpoint(\"demographic_context\")\n",
    "\n",
    "# If not, add demographic context\n",
    "if demographic_context_df is None and expanded_questions_df is not None:\n",
    "    # Start with the expanded questions\n",
    "    demographic_context_df = expanded_questions_df.copy()\n",
    "    \n",
    "    # Add demographic context columns\n",
    "    demographic_context_df['Comorbidities'] = None\n",
    "    demographic_context_df['ConditionDemographicRiskNotes'] = None\n",
    "    \n",
    "    # Update demographic context for each condition\n",
    "    # This is a simplified example - in a real scenario, this would be based on medical literature\n",
    "    demographic_updates = {\n",
    "        'Endometriosis': {\n",
    "            'Comorbidities': 'Irritable Bowel Syndrome; Migraine; Autoimmune Disorders',\n",
    "            'ConditionDemographicRiskNotes': 'More commonly diagnosed in white women; often delayed diagnosis in women of color.'\n",
    "        },\n",
    "        'Chronic Fatigue Syndrome': {\n",
    "            'Comorbidities': 'Fibromyalgia; Depression; Anxiety',\n",
    "            'ConditionDemographicRiskNotes': 'More common in women aged 30-50; often misdiagnosed as depression.'\n",
    "        },\n",
    "        'Migraine': {\n",
    "            'Comorbidities': 'Depression; Anxiety; Irritable Bowel Syndrome',\n",
    "            'ConditionDemographicRiskNotes': '3x more common in women than men; often hormonal component.'\n",
    "        },\n",
    "        'Hashimoto\\'s Thyroiditis': {\n",
    "            'Comorbidities': 'Celiac Disease; Rheumatoid Arthritis; Vitiligo',\n",
    "            'ConditionDemographicRiskNotes': '8x more common in women; peak onset age 30-50.'\n",
    "        },\n",
    "        'Rheumatoid Arthritis': {\n",
    "            'Comorbidities': 'Cardiovascular Disease; Osteoporosis; Depression',\n",
    "            'ConditionDemographicRiskNotes': '2-3x more common in women; Native American populations have higher prevalence.'\n",
    "        },\n",
    "        'Perimenopause': {\n",
    "            'Comorbidities': 'Insomnia; Depression; Osteopenia',\n",
    "            'ConditionDemographicRiskNotes': 'Average onset age 47; earlier onset in smokers and those with family history of early menopause.'\n",
    "        },\n",
    "        'Postpartum Depression': {\n",
    "            'Comorbidities': 'Anxiety; PTSD; Thyroid Dysfunction',\n",
    "            'ConditionDemographicRiskNotes': 'Higher risk in women with history of depression; socioeconomic factors influence diagnosis rates.'\n",
    "        },\n",
    "        'Vulvodynia': {\n",
    "            'Comorbidities': 'Irritable Bowel Syndrome; Fibromyalgia; Interstitial Cystitis',\n",
    "            'ConditionDemographicRiskNotes': 'Affects up to 16% of women; often undiagnosed in women of color.'\n",
    "        },\n",
    "        'Coronary Artery Disease': {\n",
    "            'Comorbidities': 'Hypertension; Diabetes; Hyperlipidemia',\n",
    "            'ConditionDemographicRiskNotes': 'Leading cause of death in women; different symptoms than men; Black women at higher risk.'\n",
    "        },\n",
    "        'Irritable Bowel Syndrome': {\n",
    "            'Comorbidities': 'Anxiety; Depression; Fibromyalgia',\n",
    "            'ConditionDemographicRiskNotes': '2x more common in women; often exacerbated by hormonal fluctuations.'\n",
    "        },\n",
    "        'Infertility': {\n",
    "            'Comorbidities': 'PCOS; Endometriosis; Thyroid Disorders',\n",
    "            'ConditionDemographicRiskNotes': 'Age is primary factor; Black and Hispanic women less likely to receive treatment.'\n",
    "        },\n",
    "        'Abnormal Uterine Bleeding': {\n",
    "            'Comorbidities': 'Fibroids; Polyps; Endometriosis',\n",
    "            'ConditionDemographicRiskNotes': 'Fibroids more common in Black women; endometrial cancer risk increases with age.'\n",
    "        },\n",
    "        'Perimenopausal Cognitive Changes': {\n",
    "            'Comorbidities': 'Insomnia; Depression; Anxiety',\n",
    "            'ConditionDemographicRiskNotes': 'Affects up to 60% of perimenopausal women; often dismissed as \"normal aging\".'\n",
    "        },\n",
    "        'Female Pattern Hair Loss': {\n",
    "            'Comorbidities': 'PCOS; Thyroid Disorders; Iron Deficiency',\n",
    "            'ConditionDemographicRiskNotes': 'Affects up to 50% of women by age 50; different pattern than male baldness.'\n",
    "        },\n",
    "        'Generalized Anxiety Disorder': {\n",
    "            'Comorbidities': 'Depression; Insomnia; Irritable Bowel Syndrome',\n",
    "            'ConditionDemographicRiskNotes': '2x more common in women; often comorbid with hormonal conditions.'\n",
    "        },\n",
    "        'Breast Mass': {\n",
    "            'Comorbidities': 'Fibrocystic Breast Changes; Mastalgia; Nipple Discharge',\n",
    "            'ConditionDemographicRiskNotes': 'Black women more likely to develop aggressive breast cancer at younger age; Ashkenazi Jewish women higher BRCA risk.'\n",
    "        },\n",
    "        'Perimenopausal Insomnia': {\n",
    "            'Comorbidities': 'Hot Flashes; Anxiety; Depression',\n",
    "            'ConditionDemographicRiskNotes': 'Affects up to 60% of perimenopausal women; often undertreated.'\n",
    "        },\n",
    "        'Postpartum Dyspareunia': {\n",
    "            'Comorbidities': 'Pelvic Floor Dysfunction; Vaginal Dryness; Perineal Trauma',\n",
    "            'ConditionDemographicRiskNotes': 'Affects up to 45% of women after childbirth; risk increases with instrumental delivery.'\n",
    "        },\n",
    "        'Postural Orthostatic Tachycardia Syndrome': {\n",
    "            'Comorbidities': 'Ehlers-Danlos Syndrome; Chronic Fatigue Syndrome; Mast Cell Activation Syndrome',\n",
    "            'ConditionDemographicRiskNotes': '5:1 female to male ratio; often triggered after pregnancy or viral illness.'\n",
    "        },\n",
    "        'Female Sexual Interest/Arousal Disorder': {\n",
    "            'Comorbidities': 'Depression; Relationship Issues; Hormonal Imbalances',\n",
    "            'ConditionDemographicRiskNotes': 'Affects 10% of women; increases with age but often not addressed by healthcare providers.'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Update the dataframe with demographic context\n",
    "    for index, row in demographic_context_df.iterrows():\n",
    "        condition = row['Condition']\n",
    "        if condition in demographic_updates:\n",
    "            demographic_context_df.at[index, 'Comorbidities'] = demographic_updates[condition]['Comorbidities']\n",
    "            demographic_context_df.at[index, 'ConditionDemographicRiskNotes'] = demographic_updates[condition]['ConditionDemographicRiskNotes']\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(demographic_context_df, \"demographic_context\")\n",
    "else:\n",
    "    print(\"Using existing demographic context data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the demographic context data\n",
    "if demographic_context_df is not None:\n",
    "    verify_dataframe(demographic_context_df, \"Demographic Context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the age group distribution\n",
    "if demographic_context_df is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Define the order for age groups\n",
    "    order = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    \n",
    "    # Count the age groups\n",
    "    age_counts = demographic_context_df['AgeGroup'].value_counts().reindex(order)\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(age_counts.index, age_counts.values, \n",
    "                   color=sns.color_palette(\"Blues_d\", len(age_counts)))\n",
    "    \n",
    "    plt.title('Distribution of Age Groups', fontsize=16)\n",
    "    plt.xlabel('Age Group', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'age_group_distribution.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the racial/ethnic considerations distribution\n",
    "if demographic_context_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Count the racial/ethnic considerations\n",
    "    racial_counts = demographic_context_df['RacialEthnicConsiderations'].value_counts()\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(racial_counts.index, racial_counts.values, \n",
    "                   color=sns.color_palette(\"Spectral\", len(racial_counts)))\n",
    "    \n",
    "    plt.title('Distribution of Racial/Ethnic Considerations', fontsize=16)\n",
    "    plt.xlabel('Racial/Ethnic Group', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'racial_ethnic_distribution.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Expanded Dataset\n",
    "\n",
    "Now let's analyze the expanded dataset with demographic context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the analyzed expanded data\n",
    "analyzed_expanded_df = load_checkpoint(\"analyzed_expanded\")\n",
    "\n",
    "# If not, analyze the expanded dataset\n",
    "if analyzed_expanded_df is None and demographic_context_df is not None:\n",
    "    # Create a copy of the demographic context dataframe\n",
    "    analyzed_expanded_df = demographic_context_df.copy()\n",
    "    \n",
    "    # Calculate the length of each question\n",
    "    analyzed_expanded_df['DismissedQuestion_Length'] = analyzed_expanded_df['DismissedQuestion'].str.len()\n",
    "    analyzed_expanded_df['BetterQuestion_Length'] = analyzed_expanded_df['BetterQuestion'].str.len()\n",
    "    \n",
    "    # Calculate the ratio of better question length to dismissed question length\n",
    "    analyzed_expanded_df['Question_Length_Ratio'] = analyzed_expanded_df['BetterQuestion_Length'] / analyzed_expanded_df['DismissedQuestion_Length']\n",
    "    \n",
    "    # Preprocess the questions for text analysis\n",
    "    analyzed_expanded_df['DismissedQuestion_Processed'] = analyzed_expanded_df['DismissedQuestion'].apply(preprocess_text)\n",
    "    analyzed_expanded_df['BetterQuestion_Processed'] = analyzed_expanded_df['BetterQuestion'].apply(preprocess_text)\n",
    "    \n",
    "    # Calculate the similarity between dismissed and better questions\n",
    "    analyzed_expanded_df['Question_Similarity'] = analyzed_expanded_df.apply(\n",
    "        lambda row: calculate_text_similarity(row['DismissedQuestion_Processed'], row['BetterQuestion_Processed']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Extract medical terms from the questions\n",
    "    # We'll use the medical terminology dataframe to identify medical terms\n",
    "    if medical_terminology_df is not None:\n",
    "        medical_terms = medical_terminology_df['Term'].str.lower().tolist()\n",
    "        \n",
    "        # Function to count medical terms in a text\n",
    "        def count_medical_terms(text, terms):\n",
    "            if not isinstance(text, str):\n",
    "                return 0\n",
    "            text_lower = text.lower()\n",
    "            count = sum(1 for term in terms if term.lower() in text_lower)\n",
    "            return count\n",
    "        \n",
    "        # Count medical terms in each question\n",
    "        analyzed_expanded_df['DismissedQuestion_MedicalTerms'] = analyzed_expanded_df['DismissedQuestion'].apply(\n",
    "            lambda x: count_medical_terms(x, medical_terms)\n",
    "        )\n",
    "        analyzed_expanded_df['BetterQuestion_MedicalTerms'] = analyzed_expanded_df['BetterQuestion'].apply(\n",
    "            lambda x: count_medical_terms(x, medical_terms)\n",
    "        )\n",
    "        \n",
    "        # Calculate the difference in medical terms\n",
    "        analyzed_expanded_df['MedicalTerms_Difference'] = analyzed_expanded_df['BetterQuestion_MedicalTerms'] - analyzed_expanded_df['DismissedQuestion_MedicalTerms']\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(analyzed_expanded_df, \"analyzed_expanded\")\n",
    "else:\n",
    "    print(\"Using existing analyzed expanded data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the analyzed expanded data\n",
    "if analyzed_expanded_df is not None:\n",
    "    verify_dataframe(analyzed_expanded_df, \"Analyzed Expanded Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the question length ratio by category\n",
    "if analyzed_expanded_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate the average question length ratio by category\n",
    "    category_ratios = analyzed_expanded_df.groupby('Category')['Question_Length_Ratio'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(category_ratios.index, category_ratios.values, \n",
    "                   color=sns.color_palette(\"viridis\", len(category_ratios)))\n",
    "    \n",
    "    plt.title('Average Question Length Ratio by Category', fontsize=16)\n",
    "    plt.xlabel('Category', fontsize=12)\n",
    "    plt.ylabel('Average Length Ratio (Better/Dismissed)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{height:.1f}x',\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'question_length_ratio_by_category.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dismissal frequency by category\n",
    "if analyzed_expanded_df is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create a cross-tabulation of category and dismissal frequency\n",
    "    dismissal_by_category = pd.crosstab(analyzed_expanded_df['Category'], analyzed_expanded_df['DismissalFrequency'])\n",
    "    \n",
    "    # Reorder the columns\n",
    "    order = ['Very High', 'High', 'Medium', 'Low']\n",
    "    dismissal_by_category = dismissal_by_category.reindex(columns=order)\n",
    "    \n",
    "    # Create a stacked bar chart\n",
    "    dismissal_by_category.plot(kind='barh', stacked=True, figsize=(12, 8),\n",
    "                              color=['#d62728', '#ff7f0e', '#ffbb78', '#2ca02c'])\n",
    "    \n",
    "    plt.title('Dismissal Frequency by Category', fontsize=16)\n",
    "    plt.xlabel('Count', fontsize=12)\n",
    "    plt.ylabel('Category', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.legend(title='Dismissal Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'dismissal_frequency_by_category.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the diagnosis delay by category\n",
    "if analyzed_expanded_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate the average diagnosis delay by category\n",
    "    category_delays = analyzed_expanded_df.groupby('Category')['DiagnosisDelay'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(category_delays.index, category_delays.values, \n",
    "                   color=sns.color_palette(\"Reds_r\", len(category_delays)))\n",
    "    \n",
    "    plt.title('Average Diagnosis Delay by Category', fontsize=16)\n",
    "    plt.xlabel('Category', fontsize=12)\n",
    "    plt.ylabel('Average Diagnosis Delay (years)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{height:.1f}',\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, 'diagnosis_delay_by_category.png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prepare Data for Next Notebook\n",
    "\n",
    "Let's save the preprocessed data for use in the next notebook in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the analyzed expanded dataset to the expanded directory\n",
    "if analyzed_expanded_df is not None:\n",
    "    analyzed_expanded_df.to_csv(os.path.join(expanded_dir, 'analyzed_expanded_dataset.csv'), index=False)\n",
    "    print(f\"Saved analyzed expanded dataset to: {os.path.join(expanded_dir, 'analyzed_expanded_dataset.csv')}\")\n",
    "\n",
    "# Save the medical terminology data to the expanded directory\n",
    "if medical_terminology_df is not None:\n",
    "    medical_terminology_df.to_csv(os.path.join(expanded_dir, 'medical_terminology.csv'), index=False)\n",
    "    print(f\"Saved medical terminology data to: {os.path.join(expanded_dir, 'medical_terminology.csv')}\")\n",
    "\n",
    "# Save the clinical trials data to the expanded directory\n",
    "if clinical_trials_df is not None:\n",
    "    clinical_trials_df.to_csv(os.path.join(expanded_dir, 'clinical_trials.csv'), index=False)\n",
    "    print(f\"Saved clinical trials data to: {os.path.join(expanded_dir, 'clinical_trials.csv')}\")\n",
    "\n",
    "# Save the PubMed data to the expanded directory\n",
    "if pubmed_df is not None:\n",
    "    pubmed_df.to_csv(os.path.join(expanded_dir, 'pubmed.csv'), index=False)\n",
    "    print(f\"Saved PubMed data to: {os.path.join(expanded_dir, 'pubmed.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of the preprocessing results\n",
    "preprocessing_summary = {\n",
    "    \"original_dismissed_questions\": len(dismissed_questions_df) if dismissed_questions_df is not None else 0,\n",
    "    \"expanded_dismissed_questions\": len(expanded_questions_df) if expanded_questions_df is not None else 0,\n",
    "    \"demographic_context_added\": True if demographic_context_df is not None else False,\n",
    "    \"question_analysis\": {\n",
    "        \"avg_dismissed_length\": analyzed_expanded_df['DismissedQuestion_Length'].mean() if analyzed_expanded_df is not None else None,\n",
    "        \"avg_better_length\": analyzed_expanded_df['BetterQuestion_Length'].mean() if analyzed_expanded_df is not None else None,\n",
    "        \"avg_length_ratio\": analyzed_expanded_df['Question_Length_Ratio'].mean() if analyzed_expanded_df is not None else None,\n",
    "        \"avg_similarity\": analyzed_expanded_df['Question_Similarity'].mean() if analyzed_expanded_df is not None else None,\n",
    "        \"avg_medical_terms_difference\": analyzed_expanded_df['MedicalTerms_Difference'].mean() if analyzed_expanded_df is not None and 'MedicalTerms_Difference' in analyzed_expanded_df.columns else None\n",
    "    },\n",
    "    \"categories\": list(analyzed_expanded_df['Category'].unique()) if analyzed_expanded_df is not None else [],\n",
    "    \"age_groups\": list(analyzed_expanded_df['AgeGroup'].unique()) if analyzed_expanded_df is not None else [],\n",
    "    \"racial_ethnic_groups\": list(analyzed_expanded_df['RacialEthnicConsiderations'].unique()) if analyzed_expanded_df is not None else []\n",
    "}\n",
    "\n",
    "# Save the summary as JSON\n",
    "with open(os.path.join(expanded_dir, 'preprocessing_summary.json'), 'w') as f:\n",
    "    json.dump(preprocessing_summary, f, indent=2)\n",
    "\n",
    "print(\"Preprocessing summary saved to:\", os.path.join(expanded_dir, 'preprocessing_summary.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the preprocessing summary\n",
    "print(\"\\n--- Preprocessing Summary ---\")\n",
    "print(f\"Original Dismissed Questions: {preprocessing_summary['original_dismissed_questions']}\")\n",
    "print(f\"Expanded Dismissed Questions: {preprocessing_summary['expanded_dismissed_questions']}\")\n",
    "print(f\"Demographic Context Added: {preprocessing_summary['demographic_context_added']}\")\n",
    "print(\"\\nQuestion Analysis:\")\n",
    "print(f\"  Average Dismissed Question Length: {preprocessing_summary['question_analysis']['avg_dismissed_length']:.1f} characters\")\n",
    "print(f\"  Average Better Question Length: {preprocessing_summary['question_analysis']['avg_better_length']:.1f} characters\")\n",
    "print(f\"  Average Length Ratio: {preprocessing_summary['question_analysis']['avg_length_ratio']:.1f}x\")\n",
    "print(f\"  Average Question Similarity: {preprocessing_summary['question_analysis']['avg_similarity']:.2f}\")\n",
    "print(f\"  Average Medical Terms Difference: {preprocessing_summary['question_analysis']['avg_medical_terms_difference']:.1f}\")\n",
    "print(\"\\nCategories:\")\n",
    "for category in preprocessing_summary['categories']:\n",
    "    print(f\"  - {category}\")\n",
    "print(\"\\nAge Groups:\")\n",
    "for age_group in preprocessing_summary['age_groups']:\n",
    "    print(f\"  - {age_group}\")\n",
    "print(\"\\nRacial/Ethnic Groups:\")\n",
    "for racial_group in preprocessing_summary['racial_ethnic_groups']:\n",
    "    print(f\"  - {racial_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've successfully preprocessed the data collected in Part 1 for our women's health LLM model:\n",
    "\n",
    "1. **Analyzed Question Characteristics**: We analyzed the differences between dismissed questions and better questions, finding that better questions are significantly longer and contain more medical terminology.\n",
    "\n",
    "2. **Expanded the Dataset**: We expanded the dismissed questions dataset to include more examples across different categories, increasing the diversity of conditions covered.\n",
    "\n",
    "3. **Added Demographic Context**: We added demographic context to the dataset, including comorbidities and condition-specific demographic risk notes.\n",
    "\n",
    "4. **Analyzed Patterns**: We identified patterns in dismissal frequency and diagnosis delay across different categories, which will help our LLM model generate more effective questions for conditions that are frequently dismissed.\n",
    "\n",
    "This preprocessed data will serve as the foundation for the next steps in our project: analysis and visualization, and training split preparation.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook (Part 3: Analysis and Visualization), we will:\n",
    "- Perform in-depth analysis of the preprocessed data\n",
    "- Create visualizations to better understand patterns in women's health questions\n",
    "- Identify key factors that contribute to question effectiveness\n",
    "- Prepare the data for the final step: training split preparation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
